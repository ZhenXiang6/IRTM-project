{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy tqdm transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "cuDNN Enabled: True\n",
      "cuDNN Version: 90501\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"cuDNN Enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"cuDNN Version:\", torch.backends.cudnn.version())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0.dev20241221+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA Library Imported Successfully\n"
     ]
    }
   ],
   "source": [
    "import ta\n",
    "print(\"TA Library Imported Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "cuDNN Enabled: True\n",
      "cuDNN Version: 90501\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 測試 CUDA 是否可用\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# 測試 GPU 名稱\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# 測試 cuDNN\n",
    "print(\"cuDNN Enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"cuDNN Version:\", torch.backends.cudnn.version())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "# 設定資料夾路徑\n",
    "articles_dir = r'C:\\Users\\morri\\Desktop\\IRTM-project\\articles'  # 替換為實際路徑\n",
    "\n",
    "# 初始化 BERT Tokenizer 和模型（以 FinBERT 為例）\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "# 確保模型在評估模式\n",
    "model.eval()\n",
    "\n",
    "# 使用 GPU 如果可用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 儲存每日情緒的列表\n",
    "daily_sentiments = []\n",
    "\n",
    "# 定義清理文本的函數\n",
    "def clean_text(text):\n",
    "    # 去除版權信息、商標符號等\n",
    "    text = re.sub(r'©\\s*\\d{4}.*?All Rights Reserved\\.', '', text)\n",
    "    text = re.sub(r'\\s*&\\s*©\\s*\\d{4}.*?All Rights Reserved\\.', '', text)\n",
    "    # 去除其他不需要的部分（根據需要調整）\n",
    "    text = re.sub(r'\\s+', ' ', text)  # 將多個空白字元替換為一個空白\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# 定義批次處理的函數\n",
    "def process_batch(texts, tokenizer, model, device, max_length=512):\n",
    "    inputs = tokenizer(texts, return_tensors='pt', truncation=True, padding=True, max_length=max_length)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # 假設模型有三個類別：positive, neutral, negative\n",
    "        sentiment_scores = probs[:, 0].cpu().numpy() - probs[:, 2].cpu().numpy()  # positive - negative\n",
    "    return sentiment_scores\n",
    "\n",
    "# 初始化全局文章計數器\n",
    "global_article_count = 0\n",
    "\n",
    "# 定義進度間隔\n",
    "progress_interval = 100  # 每100篇輸出一次\n",
    "# 若想每1000篇輸出一次，將上行改為 progress_interval = 1000\n",
    "\n",
    "# 獲取所有日期資料夾，並排序（確保時間順序）\n",
    "date_folders = sorted([folder for folder in os.listdir(articles_dir) if os.path.isdir(os.path.join(articles_dir, folder))])\n",
    "\n",
    "# 使用外層 tqdm 顯示日期進度\n",
    "for date_folder in tqdm(date_folders, desc=\"Processing Dates\"):\n",
    "    date_path = os.path.join(articles_dir, date_folder)\n",
    "    sentiments = []\n",
    "    texts = []\n",
    "    \n",
    "    # 使用內層 tqdm 顯示當日文章進度\n",
    "    article_files = sorted([file for file in os.listdir(date_path) if os.path.isfile(os.path.join(date_path, file))])\n",
    "    for article_file in tqdm(article_files, desc=f\"Processing {date_folder}\", leave=False):\n",
    "        article_path = os.path.join(date_path, article_file)\n",
    "        try:\n",
    "            with open(article_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "            # 資料清洗\n",
    "            cleaned_text = clean_text(text)\n",
    "            \n",
    "            # 若清洗後文本過短，則跳過\n",
    "            if len(cleaned_text) < 10:\n",
    "                continue\n",
    "            texts.append(cleaned_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {article_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 批次處理\n",
    "    batch_size = 32  # 根據 GPU 記憶體調整\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_sentiments = process_batch(batch_texts, tokenizer, model, device)\n",
    "        sentiments.extend(batch_sentiments)\n",
    "        \n",
    "        # 更新全局文章計數器\n",
    "        global_article_count += len(batch_texts)\n",
    "        \n",
    "        # 檢查是否達到進度顯示的間隔\n",
    "        if global_article_count % progress_interval < batch_size:\n",
    "            print(f'Processed {global_article_count} articles so far.')\n",
    "    \n",
    "    # 計算當日平均情緒分數\n",
    "    if sentiments:\n",
    "        average_sentiment = sum(sentiments) / len(sentiments)\n",
    "    else:\n",
    "        average_sentiment = 0  # 若無文章，設定為0或其他適當值\n",
    "\n",
    "    daily_sentiments.append({\n",
    "        'date': date_folder,\n",
    "        'average_sentiment': average_sentiment,\n",
    "        'num_articles': len(sentiments)\n",
    "    })\n",
    "\n",
    "# 轉換為 DataFrame\n",
    "sentiment_df = pd.DataFrame(daily_sentiments)\n",
    "\n",
    "# 儲存為 CSV（可選）\n",
    "sentiment_df.to_csv('daily_sentiments.csv', index=False)\n",
    "\n",
    "print(\"Completed processing all articles.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
