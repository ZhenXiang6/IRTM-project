{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: kernel kernelspec migrate run troubleshoot\n",
      "\n",
      "Jupyter command `jupyter-nbconvert` not found.\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script first_code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有套件匯入完成。\n"
     ]
    }
   ],
   "source": [
    "# ============================== #\n",
    "#         匯入必要的套件         #\n",
    "# ============================== #\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 設定顯示選項\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"所有套件匯入完成。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "        CUDA 測試程式碼開始        \n",
      "===================================\n",
      "PyTorch 版本: 2.6.0.dev20241221+cu126\n",
      "CUDA 可用: True\n",
      "CUDA 驅動版本: 12.6\n",
      "CUDA CUDNN 版本: 90501\n",
      "CUDA 設備數量: 1\n",
      "CUDA 設備 0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "當前使用的 CUDA 設備: 0\n",
      "===================================\n",
      "          CUDA 測試程式碼結束       \n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "print(\"===================================\")\n",
    "print(\"        CUDA 測試程式碼開始        \")\n",
    "print(\"===================================\")\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA 驅動版本: {torch.version.cuda}\")\n",
    "    print(f\"CUDA CUDNN 版本: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"CUDA 設備數量: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"CUDA 設備 {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"當前使用的 CUDA 設備: {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"CUDA 不可用。請檢查以下幾點：\")\n",
    "    print(\"1. 確保已安裝 NVIDIA GPU 驅動程序。\")\n",
    "    print(\"2. 確保已安裝與 GPU 驅動程序匹配的 CUDA Toolkit。\")\n",
    "    print(\"3. 確保已安裝支持 CUDA 的 PyTorch 版本。\")\n",
    "    print(\"4. 確保您的環境中沒有其他導致 CUDA 初始化錯誤的問題。\")\n",
    "\n",
    "print(\"===================================\")\n",
    "print(\"          CUDA 測試程式碼結束       \")\n",
    "print(\"===================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== #\n",
    "#       定義輔助函數               #\n",
    "# ============================== #\n",
    "\n",
    "def clean_text(txt: str) -> str:\n",
    "    \"\"\"簡單文本清理，去除多餘空白和雜訊。\"\"\"\n",
    "    if not isinstance(txt, str):\n",
    "        return \"\"\n",
    "    txt = re.sub(r'\\s+', ' ', txt)\n",
    "    return txt.strip()\n",
    "\n",
    "def parse_cnbc_time(t):\n",
    "    \"\"\"解析 CNBC 的時間格式: '7:51 PM ET Fri, 17 July 2020'\"\"\"\n",
    "    if not isinstance(t, str):\n",
    "        return None\n",
    "    try:\n",
    "        dt = datetime.strptime(t, '%I:%M %p ET %a, %d %B %Y')\n",
    "        return dt.strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_guardian_time(t):\n",
    "    \"\"\"解析 Guardian 的時間格式: '18-Jul-20'\"\"\"\n",
    "    if not isinstance(t, str):\n",
    "        return None\n",
    "    try:\n",
    "        dt = datetime.strptime(t.strip(), '%d-%b-%y')\n",
    "        return dt.strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_reuters_time(t):\n",
    "    \"\"\"解析 Reuters 的時間格式: 'Jul 18 2020'\"\"\"\n",
    "    if not isinstance(t, str):\n",
    "        return None\n",
    "    try:\n",
    "        dt = datetime.strptime(t.strip(), '%b %d %Y')\n",
    "        return dt.strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def load_cnbc(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path, on_bad_lines='skip', engine='python')\n",
    "    print(f\"CNBC 原始欄位: {df.columns.tolist()}\")\n",
    "    expected_cols = ['Headlines', 'Time', 'Description']\n",
    "    for col in expected_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"警告: CNBC CSV 缺少欄位 '{col}'\")\n",
    "    df['headline'] = df['Headlines'].fillna(\"\").apply(clean_text)\n",
    "    df['article_content'] = df['Description'].fillna(\"\").apply(clean_text)\n",
    "    df['date'] = df['Time'].apply(parse_cnbc_time)\n",
    "    df = df[['date', 'headline', 'article_content']].dropna(subset=['date', 'headline'])\n",
    "    df['source'] = 'CNBC'\n",
    "    return df\n",
    "\n",
    "def load_guardian(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path, on_bad_lines='skip', engine='python')\n",
    "    print(f\"Guardian 原始欄位: {df.columns.tolist()}\")\n",
    "    expected_cols = ['Time', 'Headlines']\n",
    "    for col in expected_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"警告: Guardian CSV 缺少欄位 '{col}'\")\n",
    "    df['headline'] = df['Headlines'].fillna(\"\").apply(clean_text)\n",
    "    df['article_content'] = \"\"  # Guardian 無 Description\n",
    "    df['date'] = df['Time'].apply(parse_guardian_time)\n",
    "    df = df[['date', 'headline', 'article_content']].dropna(subset=['date', 'headline'])\n",
    "    df['source'] = 'Guardian'\n",
    "    return df\n",
    "\n",
    "def load_reuters(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path, on_bad_lines='skip', engine='python')\n",
    "    print(f\"Reuters 原始欄位: {df.columns.tolist()}\")\n",
    "    expected_cols = ['Headlines', 'Time', 'Description']\n",
    "    for col in expected_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"警告: Reuters CSV 缺少欄位 '{col}'\")\n",
    "    df['headline'] = df['Headlines'].fillna(\"\").apply(clean_text)\n",
    "    df['article_content'] = df['Description'].fillna(\"\").apply(clean_text)\n",
    "    df['date'] = df['Time'].apply(parse_reuters_time)\n",
    "    df = df[['date', 'headline', 'article_content']].dropna(subset=['date', 'headline'])\n",
    "    df['source'] = 'Reuters'\n",
    "    return df\n",
    "\n",
    "def merge_news(cnbc_csv, guardian_csv, reuters_csv):\n",
    "    \"\"\"\n",
    "    讀取並合併 CNBC、Guardian 和 Reuters 的新聞資料。\n",
    "    將 'Time' 欄位轉換為 'date'，並統一格式。\n",
    "    \"\"\"\n",
    "    # 讀取 CSV 檔案\n",
    "    cnbc = pd.read_csv(cnbc_csv)\n",
    "    guardian = pd.read_csv(guardian_csv)\n",
    "    reuters = pd.read_csv(reuters_csv)\n",
    "    \n",
    "    # 轉換 'Time' 欄位為 datetime 格式，並命名為 'date'\n",
    "    cnbc['date'] = pd.to_datetime(cnbc['Time']).dt.date\n",
    "    guardian['date'] = pd.to_datetime(guardian['Time']).dt.date\n",
    "    reuters['date'] = pd.to_datetime(reuters['Time']).dt.date\n",
    "    \n",
    "    # 選取必要欄位\n",
    "    cnbc = cnbc[['date', 'Headlines', 'Description']]\n",
    "    guardian = guardian[['date', 'Headlines']]\n",
    "    reuters = reuters[['date', 'Headlines', 'Description']]\n",
    "    \n",
    "    # 合併資料\n",
    "    df_news = pd.concat([cnbc, guardian, reuters], ignore_index=True)\n",
    "    \n",
    "    # 確保 'date' 欄位為 datetime 類型\n",
    "    df_news['date'] = pd.to_datetime(df_news['date'])\n",
    "    \n",
    "    # 排序\n",
    "    df_news.sort_values('date', inplace=True)\n",
    "    \n",
    "    # 重設索引\n",
    "    df_news.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_news\n",
    "\n",
    "\n",
    "def setup_finbert_pipeline():\n",
    "    \"\"\"初始化 FinBERT pipeline\"\"\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "    model = BertForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    finbert_pipeline = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device=device\n",
    "    )\n",
    "    print(f\"FinBERT pipeline 使用的設備: {'GPU (0)' if device == 0 else 'CPU'}\")\n",
    "    return finbert_pipeline\n",
    "\n",
    "\n",
    "def batch_sentiment(text_list, pipeline_fn, batch_size=16, max_length=128):\n",
    "    \"\"\"\n",
    "    手動分批，並使用 tqdm 進度條顯示處理進度。\n",
    "    pipeline_fn: transformers pipeline\n",
    "    text_list: 需要做情緒分析的文本列表\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(text_list), batch_size), desc=\"Sentiment Analysis Batches\"):\n",
    "        batch_texts = text_list[i:i+batch_size]\n",
    "        try:\n",
    "            batch_out = pipeline_fn(\n",
    "                batch_texts,\n",
    "                truncation=True,\n",
    "                max_length=max_length\n",
    "            )\n",
    "            for out in batch_out:\n",
    "                label = out['label'].lower()\n",
    "                score = out['score']\n",
    "                if label == 'positive':\n",
    "                    results.append(+score)\n",
    "                elif label == 'negative':\n",
    "                    results.append(-score)\n",
    "                else:\n",
    "                    results.append(0.0)\n",
    "        except Exception as e:\n",
    "            print(f\"批次 {i//batch_size + 1} 解析錯誤: {e}\")\n",
    "            results.extend([0.0]*len(batch_texts))\n",
    "    return results\n",
    "\n",
    "def compute_daily_sentiment(df_news: pd.DataFrame, sentiment_pipeline, batch_size=16, max_length=128) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    對 headline & article_content 做批次情緒分析，顯示 tqdm 進度條，並彙整成每日平均 (mean_headline_sent, mean_content_sent)。\n",
    "    \"\"\"\n",
    "    print(\"開始批次情緒分析 (FinBERT) ...\")\n",
    "\n",
    "    # headline\n",
    "    headlines = df_news['headline'].tolist()\n",
    "    print(\"-> 分析 Headline\")\n",
    "    headline_scores = batch_sentiment(headlines, sentiment_pipeline, batch_size=batch_size, max_length=max_length)\n",
    "\n",
    "    # content\n",
    "    contents = df_news['article_content'].tolist()\n",
    "    print(\"-> 分析 Content\")\n",
    "    content_scores = batch_sentiment(contents, sentiment_pipeline, batch_size=batch_size, max_length=max_length)\n",
    "\n",
    "    df_news['headline_sent'] = headline_scores\n",
    "    df_news['content_sent']  = content_scores\n",
    "\n",
    "    print(\"-> 彙整當日情緒...\")\n",
    "    daily_sentiment = (\n",
    "        df_news\n",
    "        .groupby('date')\n",
    "        .agg({'headline_sent':'mean','content_sent':'mean'})\n",
    "        .reset_index()\n",
    "        .rename(columns={\n",
    "            'headline_sent': 'mean_headline_sent',\n",
    "            'content_sent': 'mean_content_sent'\n",
    "        })\n",
    "    )\n",
    "    print(\"情緒分析完成。若出現負值，可能代表負面新聞居多。\")\n",
    "    return daily_sentiment\n",
    "\n",
    "def load_sp500(sp_csv_path: str) -> pd.DataFrame:\n",
    "    df_sp = pd.read_csv(sp_csv_path, on_bad_lines='skip', engine='python')\n",
    "    print(f\"S&P500 原始欄位: {df_sp.columns.tolist()}\")\n",
    "    df_sp.rename(columns={'Date':'date','S&P500':'sp_close'}, inplace=True)\n",
    "    df_sp['date'] = pd.to_datetime(df_sp['date']).dt.strftime('%Y-%m-%d')\n",
    "    df_sp.sort_values('date', inplace=True)\n",
    "    print(f\"S&P500 行數: {len(df_sp)}\")\n",
    "    return df_sp\n",
    "\n",
    "def create_labels_for_prediction(df: pd.DataFrame, mode='classification'):\n",
    "    \"\"\"\n",
    "    mode='classification': 隔日漲(1)/跌(0)\n",
    "    mode='regression': 預測隔日收盤價\n",
    "    \"\"\"\n",
    "    df['sp_close_next'] = df['sp_close'].shift(-1)\n",
    "    df = df.dropna(subset=['sp_close_next'])\n",
    "\n",
    "    if mode == 'classification':\n",
    "        df['target'] = (df['sp_close_next'] > df['sp_close']).astype(int)\n",
    "    else:  # regression\n",
    "        df['target'] = df['sp_close_next']\n",
    "    return df\n",
    "\n",
    "def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    添加技術指標到 DataFrame 中。\n",
    "    包括移動平均線（MA）、相對強弱指標（RSI）、移動平均收斂發散指標（MACD）、\n",
    "    Bollinger Bands 等。\n",
    "    \"\"\"\n",
    "    # 移動平均線\n",
    "    df['MA_5'] = df['sp_close'].rolling(window=5).mean()\n",
    "    df['MA_10'] = df['sp_close'].rolling(window=10).mean()\n",
    "    \n",
    "    # 相對強弱指標 (RSI)\n",
    "    delta = df['sp_close'].diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(window=14).mean()\n",
    "    loss = -delta.where(delta < 0, 0).rolling(window=14).mean()\n",
    "    RS = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + RS))\n",
    "    \n",
    "    # 移動平均收斂發散指標 (MACD)\n",
    "    ema_12 = df['sp_close'].ewm(span=12, adjust=False).mean()\n",
    "    ema_26 = df['sp_close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = ema_12 - ema_26\n",
    "    df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['BB_upper'] = df['MA_10'] + 2 * df['sp_close'].rolling(window=10).std()\n",
    "    df['BB_lower'] = df['MA_10'] - 2 * df['sp_close'].rolling(window=10).std()\n",
    "    \n",
    "    # 移動平均收斂發散指標差值\n",
    "    df['MACD_diff'] = df['MACD'] - df['MACD_signal']\n",
    "    \n",
    "    # 去除因計算技術指標產生的 NaN 值\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_sentiment_features(df: pd.DataFrame, sentiment_col='mean_headline_sent', lags=[1,2,3]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    添加情緒變動值和滯後情緒特徵。\n",
    "    \"\"\"\n",
    "    # 情緒變動值\n",
    "    df['sentiment_change_1'] = df[sentiment_col].diff(1)\n",
    "    df['sentiment_change_2'] = df[sentiment_col].diff(2)\n",
    "    df['sentiment_change_3'] = df[sentiment_col].diff(3)\n",
    "    \n",
    "    # 滯後情緒特徵\n",
    "    for lag in lags:\n",
    "        df[f'sentiment_lag_{lag}'] = df[sentiment_col].shift(lag)\n",
    "    \n",
    "    # 去除因計算差分和滯後特徵產生的 NaN 值\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_sp500_features(df: pd.DataFrame, lags=[1,2,3], rolling_window=5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    添加 S&P500 的滯後漲幅和滾動平均漲幅特徵。\n",
    "    同時添加滯後的 sp_close 特徵。\n",
    "    \"\"\"\n",
    "    # 計算每日漲幅\n",
    "    df.loc[:, 'sp_return'] = df['sp_close'].pct_change()\n",
    "    \n",
    "    # 滯後漲幅\n",
    "    for lag in lags:\n",
    "        df.loc[:, f'sp_return_lag_{lag}'] = df['sp_return'].shift(lag)\n",
    "    \n",
    "    # 滾動平均漲幅\n",
    "    df.loc[:, f'sp_return_mean_{rolling_window}'] = df['sp_return'].rolling(window=rolling_window).mean()\n",
    "    \n",
    "    # 添加滯後的 sp_close 特徵\n",
    "    for lag in lags:\n",
    "        df.loc[:, f'sp_close_lag_{lag}'] = df['sp_close'].shift(lag)\n",
    "    \n",
    "    # 去除因計算漲幅、滯後和滾動平均產生的 NaN 值\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    添加所有特徵：技術指標、情緒變動與滯後、S&P500 漲幅與滯後。\n",
    "    保留 'date' 欄位。\n",
    "    \"\"\"\n",
    "    # 添加技術指標\n",
    "    df = add_technical_indicators(df)\n",
    "    \n",
    "    # 添加情緒變動特徵和滯後特徵\n",
    "    df = add_sentiment_features(df, sentiment_col='mean_headline_sent', lags=[1,2,3])\n",
    "    \n",
    "    # 添加 S&P500 的漲幅特徵\n",
    "    df = add_sp500_features(df, lags=[1,2,3], rolling_window=5)\n",
    "    \n",
    "    # 保留 'date' 欄位\n",
    "    if 'date' not in df.columns:\n",
    "        raise KeyError(\"'date' 欄位在特徵工程後遺失。\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== #\n",
    "#        定義模型訓練函數         #\n",
    "# ============================== #\n",
    "\n",
    "def train_random_forest(X_train, y_train):\n",
    "    \"\"\"訓練 Random Forest 模型。\"\"\"\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=150,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def train_xgboost(X_train, y_train):\n",
    "    \"\"\"訓練 XGBoost 模型，使用 GPU。\"\"\"\n",
    "    clf = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=1,  # 根據類別不平衡調整\n",
    "        tree_method='gpu_hist',  # 使用 GPU\n",
    "        predictor='gpu_predictor',  # 使用 GPU 進行預測\n",
    "        gpu_id=0,  # 指定 GPU ID\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_lightgbm(X_train, y_train):\n",
    "    \"\"\"訓練 LightGBM 模型，使用 GPU。\"\"\"\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt',\n",
    "        device='gpu',\n",
    "        gpu_platform_id=0,\n",
    "        gpu_device_id=0,\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=10,               # 增加最大深度\n",
    "        num_leaves=31,              # 增加葉子節點數\n",
    "        min_data_in_leaf=10,        # 減少每葉最小樣本數\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "\n",
    "def train_catboost(X_train, y_train):\n",
    "    \"\"\"訓練 CatBoost 模型，使用 GPU。\"\"\"\n",
    "    clf = cb.CatBoostClassifier(\n",
    "        iterations=150,\n",
    "        learning_rate=0.1,\n",
    "        depth=5,\n",
    "        class_weights=[2,1],  # 根據類別不平衡調整\n",
    "        task_type='GPU',       # 使用 GPU\n",
    "        devices='0',           # 指定 GPU ID\n",
    "        verbose=0,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_mlp(X_train, y_train):\n",
    "    \"\"\"訓練 MLP 模型。\"\"\"\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 50),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def get_stacking_model():\n",
    "    \"\"\"建立 Stacking 模型，結合 Random Forest 和 Gradient Boosting。\"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators=150, random_state=42, class_weight='balanced')\n",
    "    xgb = train_xgboost  # 已修改的 XGBoost GPU 函數\n",
    "    lgbm = train_lightgbm  # 已修改的 LightGBM GPU 函數\n",
    "    catboost = train_catboost  # 已修改的 CatBoost GPU 函數\n",
    "\n",
    "    # 建立 VotingClassifier，這裡假設您已經有預先訓練的模型\n",
    "    stacking_clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf),\n",
    "            ('xgb', xgb),\n",
    "            ('lgbm', lgbm),\n",
    "            ('catboost', catboost)\n",
    "        ],\n",
    "        voting='soft'  # 使用概率投票\n",
    "    )\n",
    "    return stacking_clf\n",
    "def train_stacking(X_train, y_train):\n",
    "    \"\"\"訓練 Stacking 模型。\"\"\"\n",
    "    stacking_clf = get_stacking_model()\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    return stacking_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== #\n",
    "#      定義評估與交叉驗證函數     #\n",
    "# ============================== #\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, y_prob=None):\n",
    "    \"\"\"評估分類模型。\"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    if auc is not None:\n",
    "        print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return acc, f1, auc\n",
    "\n",
    "def timeseries_cv_and_train(X, y, model_fn, n_splits=5, is_lstm=False):\n",
    "    \"\"\"\n",
    "    使用 TimeSeriesSplit 進行交叉驗證，回傳平均 Accuracy、F1 分數和 AUC-ROC。\n",
    "    model_fn: 傳入可呼叫 (X_train, y_train) -> (model, predict_fn)\n",
    "    is_lstm: True 表示 LSTM，需要 reshape\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    acc_scores = []\n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "        print(f\"\\nFold {fold_idx+1}/{n_splits} 開始...\")\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        print(f\"Fold {fold_idx+1} - X_train shape: {X_train.shape}\")\n",
    "        print(f\"Fold {fold_idx+1} - X_val shape: {X_val.shape}\")\n",
    "        print(f\"Fold {fold_idx+1} - y_train shape: {y_train.shape}\")\n",
    "        print(f\"Fold {fold_idx+1} - y_val shape: {y_val.shape}\")\n",
    "        \n",
    "        model, pred_fn = model_fn(X_train, y_train)\n",
    "        y_pred = pred_fn(X_val)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_val)[:,1]\n",
    "        else:\n",
    "            y_prob = None\n",
    "        \n",
    "        acc, f1, auc = evaluate_classification(y_val, y_pred, y_prob)\n",
    "        acc_scores.append(acc)\n",
    "        f1_scores.append(f1)\n",
    "        auc_scores.append(auc if auc is not None else 0)\n",
    "    \n",
    "    avg_acc = np.mean(acc_scores)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_auc = np.mean(auc_scores)\n",
    "    print(f\"\\n=== TimeSeriesSplit 平均 ACC: {avg_acc:.4f}, F1: {avg_f1:.4f}, AUC-ROC: {avg_auc:.4f} ===\")\n",
    "    return avg_acc, avg_f1, avg_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment_features(df: pd.DataFrame, sentiment_col='mean_headline_sent', lags=[1,2,3]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    添加情緒變動值和滯後情緒特徵。\n",
    "    \"\"\"\n",
    "    # 使用 .loc 進行安全的賦值操作\n",
    "    df.loc[:, 'sentiment_change_1'] = df[sentiment_col].diff(1)\n",
    "    df.loc[:, 'sentiment_change_2'] = df[sentiment_col].diff(2)\n",
    "    df.loc[:, 'sentiment_change_3'] = df[sentiment_col].diff(3)\n",
    "    \n",
    "    # 滯後情緒特徵\n",
    "    for lag in lags:\n",
    "        df.loc[:, f'sentiment_lag_{lag}'] = df[sentiment_col].shift(lag)\n",
    "    \n",
    "    # 去除因計算差分和滯後特徵產生的 NaN 值\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 3 fields in line 4, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m reuters_csv  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmorri\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIRTM-project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mreuters_headlines.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 讀取並合併新聞資料\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m df_news \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_news\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnbc_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguardian_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreuters_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[News] total: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_news)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows from 3 sources.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 檢查合併後的資料\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[36], line 92\u001b[0m, in \u001b[0;36mmerge_news\u001b[1;34m(cnbc_csv, guardian_csv, reuters_csv)\u001b[0m\n\u001b[0;32m     90\u001b[0m cnbc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(cnbc_csv)\n\u001b[0;32m     91\u001b[0m guardian \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(guardian_csv)\n\u001b[1;32m---> 92\u001b[0m reuters \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreuters_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# 轉換 'Time' 欄位為 datetime 格式，並命名為 'date'\u001b[39;00m\n\u001b[0;32m     95\u001b[0m cnbc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(cnbc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 4, saw 4\n"
     ]
    }
   ],
   "source": [
    "# ============================== #\n",
    "#          主流程開始               #\n",
    "# ============================== #\n",
    "\n",
    "\n",
    "# ============================== #\n",
    "#       1. 讀取並合併新聞資料       #\n",
    "# ============================== #\n",
    "\n",
    "# 使用範例路徑（請根據您的實際檔案路徑修改）\n",
    "cnbc_csv     = r\"C:\\Users\\morri\\Desktop\\IRTM-project\\test\\cnbc_headlines.csv\"\n",
    "guardian_csv = r\"C:\\Users\\morri\\Desktop\\IRTM-project\\test\\guardian_headlines.csv\"\n",
    "reuters_csv  = r\"C:\\Users\\morri\\Desktop\\IRTM-project\\test\\reuters_headlines.csv\"\n",
    "\n",
    "# 讀取並合併新聞資料\n",
    "df_news = merge_news(cnbc_csv, guardian_csv, reuters_csv)\n",
    "print(f\"[News] total: {len(df_news)} rows from 3 sources.\")\n",
    "\n",
    "# 檢查合併後的資料\n",
    "print(\"\\n合併後的資料預覽：\")\n",
    "display(df_news.head())\n",
    "print(\"df_news 的欄位:\")\n",
    "print(df_news.columns.tolist())\n",
    "\n",
    "# ============================== #\n",
    "#     2. 初始化 FinBERT pipeline     #\n",
    "# ============================== #\n",
    "\n",
    "finbert_pipe = setup_finbert_pipeline()\n",
    "print(\"FinBERT pipeline 初始化完成。\")\n",
    "\n",
    "# ============================== #\n",
    "#      3. 批次情緒分析             #\n",
    "# ============================== #\n",
    "\n",
    "# 計算每日情緒分數\n",
    "daily_sentiment_df = compute_daily_sentiment(df_news, finbert_pipe, batch_size=32, max_length=128)\n",
    "daily_sentiment_df.to_csv(\"daily_sentiment.csv\", index=False)\n",
    "print(\"[Output] daily_sentiment.csv 已輸出.\")\n",
    "\n",
    "# ============================== #\n",
    "#        4. 讀取 S&P500 資料          #\n",
    "# ============================== #\n",
    "\n",
    "# 使用範例路徑（請根據您的實際檔案路徑修改）\n",
    "sp500_csv    = r\"C:\\Users\\morri\\Desktop\\IRTM-project\\test\\sp500_index.csv\"\n",
    "\n",
    "# 讀取 S&P500 資料\n",
    "df_sp = load_sp500(sp500_csv)\n",
    "print(f\"[SP500] total: {len(df_sp)} rows.\")\n",
    "\n",
    "# ============================== #\n",
    "#  5. 合併情緒分數與 S&P500 資料  #\n",
    "# ============================== #\n",
    "\n",
    "print(\"\\n合併情緒分數與 S&P500 資料...\")\n",
    "df_merged = pd.merge(daily_sentiment_df, df_sp, on='date', how='inner')\n",
    "df_merged.sort_values('date', inplace=True)\n",
    "df_merged.dropna(inplace=True)\n",
    "print(f\"[Merged] total: {len(df_merged)} rows.\")\n",
    "\n",
    "# 檢查合併後的資料\n",
    "print(\"\\n合併後的資料預覽：\")\n",
    "display(df_merged.head())\n",
    "\n",
    "# ============================== #\n",
    "#      6. 建立標籤 (隔日漲跌)       #\n",
    "# ============================== #\n",
    "\n",
    "print(\"\\n建立標籤 (隔日漲跌)...\")\n",
    "df_merged = create_labels_for_prediction(df_merged, mode='classification')\n",
    "print(f\"[Merged+Target] total: {len(df_merged)} rows with target.\")\n",
    "\n",
    "# 檢查建立標籤後的資料\n",
    "print(\"\\n建立標籤後的資料預覽：\")\n",
    "display(df_merged.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "添加所有特徵後的資料預覽：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mean_headline_sent</th>\n",
       "      <th>mean_content_sent</th>\n",
       "      <th>sp_close</th>\n",
       "      <th>sp_close_next</th>\n",
       "      <th>target</th>\n",
       "      <th>MA_5</th>\n",
       "      <th>MA_10</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>BB_upper</th>\n",
       "      <th>BB_lower</th>\n",
       "      <th>MACD_diff</th>\n",
       "      <th>sentiment_change_1</th>\n",
       "      <th>sentiment_change_2</th>\n",
       "      <th>sentiment_change_3</th>\n",
       "      <th>sentiment_lag_1</th>\n",
       "      <th>sentiment_lag_2</th>\n",
       "      <th>sentiment_lag_3</th>\n",
       "      <th>sp_return</th>\n",
       "      <th>sp_return_lag_1</th>\n",
       "      <th>sp_return_lag_2</th>\n",
       "      <th>sp_return_lag_3</th>\n",
       "      <th>sp_return_mean_5</th>\n",
       "      <th>sp_close_lag_1</th>\n",
       "      <th>sp_close_lag_2</th>\n",
       "      <th>sp_close_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>-0.355807</td>\n",
       "      <td>-0.135176</td>\n",
       "      <td>2699.63</td>\n",
       "      <td>2716.31</td>\n",
       "      <td>1</td>\n",
       "      <td>2728.880</td>\n",
       "      <td>2751.021</td>\n",
       "      <td>26.277666</td>\n",
       "      <td>3.077169</td>\n",
       "      <td>13.039142</td>\n",
       "      <td>2808.053551</td>\n",
       "      <td>2693.988449</td>\n",
       "      <td>-9.961972</td>\n",
       "      <td>-0.170921</td>\n",
       "      <td>-0.126648</td>\n",
       "      <td>-0.324425</td>\n",
       "      <td>-0.184886</td>\n",
       "      <td>-0.229160</td>\n",
       "      <td>-0.031382</td>\n",
       "      <td>-0.008604</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>-0.013725</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>2723.06</td>\n",
       "      <td>2717.07</td>\n",
       "      <td>2754.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>-0.130231</td>\n",
       "      <td>-0.103730</td>\n",
       "      <td>2716.31</td>\n",
       "      <td>2718.37</td>\n",
       "      <td>1</td>\n",
       "      <td>2722.190</td>\n",
       "      <td>2744.403</td>\n",
       "      <td>30.040733</td>\n",
       "      <td>0.809837</td>\n",
       "      <td>10.593281</td>\n",
       "      <td>2800.558253</td>\n",
       "      <td>2688.247747</td>\n",
       "      <td>-9.783444</td>\n",
       "      <td>0.225576</td>\n",
       "      <td>0.054655</td>\n",
       "      <td>0.098928</td>\n",
       "      <td>-0.355807</td>\n",
       "      <td>-0.184886</td>\n",
       "      <td>-0.229160</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.008604</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>-0.013725</td>\n",
       "      <td>-0.002417</td>\n",
       "      <td>2699.63</td>\n",
       "      <td>2723.06</td>\n",
       "      <td>2717.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2018-06-29</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.090418</td>\n",
       "      <td>2718.37</td>\n",
       "      <td>2726.71</td>\n",
       "      <td>1</td>\n",
       "      <td>2714.888</td>\n",
       "      <td>2738.274</td>\n",
       "      <td>29.633186</td>\n",
       "      <td>-0.811462</td>\n",
       "      <td>8.312332</td>\n",
       "      <td>2790.573108</td>\n",
       "      <td>2685.974892</td>\n",
       "      <td>-9.123794</td>\n",
       "      <td>0.130065</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.184720</td>\n",
       "      <td>-0.130231</td>\n",
       "      <td>-0.355807</td>\n",
       "      <td>-0.184886</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.008604</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>-0.002637</td>\n",
       "      <td>2716.31</td>\n",
       "      <td>2699.63</td>\n",
       "      <td>2723.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>-0.117394</td>\n",
       "      <td>-0.172609</td>\n",
       "      <td>2726.71</td>\n",
       "      <td>2713.22</td>\n",
       "      <td>0</td>\n",
       "      <td>2716.816</td>\n",
       "      <td>2733.570</td>\n",
       "      <td>31.170946</td>\n",
       "      <td>-1.407164</td>\n",
       "      <td>6.368433</td>\n",
       "      <td>2779.796957</td>\n",
       "      <td>2687.343043</td>\n",
       "      <td>-7.775597</td>\n",
       "      <td>-0.117228</td>\n",
       "      <td>0.012837</td>\n",
       "      <td>0.238413</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.130231</td>\n",
       "      <td>-0.355807</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.008604</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>2718.37</td>\n",
       "      <td>2716.31</td>\n",
       "      <td>2699.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>-0.123707</td>\n",
       "      <td>-0.146778</td>\n",
       "      <td>2713.22</td>\n",
       "      <td>2736.61</td>\n",
       "      <td>1</td>\n",
       "      <td>2714.848</td>\n",
       "      <td>2728.633</td>\n",
       "      <td>30.734087</td>\n",
       "      <td>-2.933971</td>\n",
       "      <td>4.507952</td>\n",
       "      <td>2771.509144</td>\n",
       "      <td>2685.756856</td>\n",
       "      <td>-7.441923</td>\n",
       "      <td>-0.006312</td>\n",
       "      <td>-0.123541</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>-0.117394</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.130231</td>\n",
       "      <td>-0.004947</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>2726.71</td>\n",
       "      <td>2718.37</td>\n",
       "      <td>2716.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  mean_headline_sent  mean_content_sent  sp_close  \\\n",
       "126  2018-06-27           -0.355807          -0.135176   2699.63   \n",
       "127  2018-06-28           -0.130231          -0.103730   2716.31   \n",
       "128  2018-06-29           -0.000166          -0.090418   2718.37   \n",
       "129  2018-07-02           -0.117394          -0.172609   2726.71   \n",
       "130  2018-07-03           -0.123707          -0.146778   2713.22   \n",
       "\n",
       "     sp_close_next  target      MA_5     MA_10        RSI      MACD  \\\n",
       "126        2716.31       1  2728.880  2751.021  26.277666  3.077169   \n",
       "127        2718.37       1  2722.190  2744.403  30.040733  0.809837   \n",
       "128        2726.71       1  2714.888  2738.274  29.633186 -0.811462   \n",
       "129        2713.22       0  2716.816  2733.570  31.170946 -1.407164   \n",
       "130        2736.61       1  2714.848  2728.633  30.734087 -2.933971   \n",
       "\n",
       "     MACD_signal     BB_upper     BB_lower  MACD_diff  sentiment_change_1  \\\n",
       "126    13.039142  2808.053551  2693.988449  -9.961972           -0.170921   \n",
       "127    10.593281  2800.558253  2688.247747  -9.783444            0.225576   \n",
       "128     8.312332  2790.573108  2685.974892  -9.123794            0.130065   \n",
       "129     6.368433  2779.796957  2687.343043  -7.775597           -0.117228   \n",
       "130     4.507952  2771.509144  2685.756856  -7.441923           -0.006312   \n",
       "\n",
       "     sentiment_change_2  sentiment_change_3  sentiment_lag_1  sentiment_lag_2  \\\n",
       "126           -0.126648           -0.324425        -0.184886        -0.229160   \n",
       "127            0.054655            0.098928        -0.355807        -0.184886   \n",
       "128            0.355641            0.184720        -0.130231        -0.355807   \n",
       "129            0.012837            0.238413        -0.000166        -0.130231   \n",
       "130           -0.123541            0.006525        -0.117394        -0.000166   \n",
       "\n",
       "     sentiment_lag_3  sp_return  sp_return_lag_1  sp_return_lag_2  \\\n",
       "126        -0.031382  -0.008604         0.002205        -0.013725   \n",
       "127        -0.229160   0.006179        -0.008604         0.002205   \n",
       "128        -0.184886   0.000758         0.006179        -0.008604   \n",
       "129        -0.355807   0.003068         0.000758         0.006179   \n",
       "130        -0.130231  -0.004947         0.003068         0.000758   \n",
       "\n",
       "     sp_return_lag_3  sp_return_mean_5  sp_close_lag_1  sp_close_lag_2  \\\n",
       "126         0.001862         -0.004922         2723.06         2717.07   \n",
       "127        -0.013725         -0.002417         2699.63         2723.06   \n",
       "128         0.002205         -0.002637         2716.31         2699.63   \n",
       "129        -0.008604          0.000721         2718.37         2716.31   \n",
       "130         0.006179         -0.000709         2726.71         2718.37   \n",
       "\n",
       "     sp_close_lag_3  \n",
       "126         2754.88  \n",
       "127         2717.07  \n",
       "128         2723.06  \n",
       "129         2699.63  \n",
       "130         2716.31  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有特徵均存在。\n",
      "[Info] 特徵標準化完成.\n",
      "X_full_scaled shape: (517, 25)\n",
      "\n",
      "=== TimeSeriesSplit: Random Forest ===\n",
      "\n",
      "Fold 1/3 開始...\n",
      "Fold 1 - X_train shape: (130, 25)\n",
      "Fold 1 - X_val shape: (129, 25)\n",
      "Fold 1 - y_train shape: (130,)\n",
      "Fold 1 - y_val shape: (129,)\n",
      "Accuracy: 0.4031\n",
      "F1 Score: 0.1149\n",
      "AUC-ROC: 0.6028\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.90      0.55        52\n",
      "           1       0.50      0.06      0.11        77\n",
      "\n",
      "    accuracy                           0.40       129\n",
      "   macro avg       0.45      0.48      0.33       129\n",
      "weighted avg       0.46      0.40      0.29       129\n",
      "\n",
      "\n",
      "Fold 2/3 開始...\n",
      "Fold 2 - X_train shape: (259, 25)\n",
      "Fold 2 - X_val shape: (129, 25)\n",
      "Fold 2 - y_train shape: (259,)\n",
      "Fold 2 - y_val shape: (129,)\n",
      "Accuracy: 0.4961\n",
      "F1 Score: 0.4961\n",
      "AUC-ROC: 0.4788\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.62      0.50        52\n",
      "           1       0.62      0.42      0.50        77\n",
      "\n",
      "    accuracy                           0.50       129\n",
      "   macro avg       0.52      0.52      0.50       129\n",
      "weighted avg       0.53      0.50      0.50       129\n",
      "\n",
      "\n",
      "Fold 3/3 開始...\n",
      "Fold 3 - X_train shape: (388, 25)\n",
      "Fold 3 - X_val shape: (129, 25)\n",
      "Fold 3 - y_train shape: (388,)\n",
      "Fold 3 - y_val shape: (129,)\n",
      "Accuracy: 0.5271\n",
      "F1 Score: 0.6554\n",
      "AUC-ROC: 0.4619\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.18      0.25        57\n",
      "           1       0.55      0.81      0.66        72\n",
      "\n",
      "    accuracy                           0.53       129\n",
      "   macro avg       0.48      0.49      0.45       129\n",
      "weighted avg       0.49      0.53      0.47       129\n",
      "\n",
      "\n",
      "=== TimeSeriesSplit 平均 ACC: 0.4755, F1: 0.4221, AUC-ROC: 0.5145 ===\n",
      "\n",
      "=== TimeSeriesSplit: XGBoost ===\n",
      "\n",
      "Fold 1/3 開始...\n",
      "Fold 1 - X_train shape: (130, 25)\n",
      "Fold 1 - X_val shape: (129, 25)\n",
      "Fold 1 - y_train shape: (130,)\n",
      "Fold 1 - y_val shape: (129,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4884\n",
      "F1 Score: 0.3774\n",
      "AUC-ROC: 0.5450\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.83      0.57        52\n",
      "           1       0.69      0.26      0.38        77\n",
      "\n",
      "    accuracy                           0.49       129\n",
      "   macro avg       0.56      0.54      0.47       129\n",
      "weighted avg       0.58      0.49      0.45       129\n",
      "\n",
      "\n",
      "Fold 2/3 開始...\n",
      "Fold 2 - X_train shape: (259, 25)\n",
      "Fold 2 - X_val shape: (129, 25)\n",
      "Fold 2 - y_train shape: (259,)\n",
      "Fold 2 - y_val shape: (129,)\n",
      "Accuracy: 0.4419\n",
      "F1 Score: 0.4194\n",
      "AUC-ROC: 0.4488\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.60      0.46        52\n",
      "           1       0.55      0.34      0.42        77\n",
      "\n",
      "    accuracy                           0.44       129\n",
      "   macro avg       0.47      0.47      0.44       129\n",
      "weighted avg       0.48      0.44      0.44       129\n",
      "\n",
      "\n",
      "Fold 3/3 開始...\n",
      "Fold 3 - X_train shape: (388, 25)\n",
      "Fold 3 - X_val shape: (129, 25)\n",
      "Fold 3 - y_train shape: (388,)\n",
      "Fold 3 - y_val shape: (129,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5349\n",
      "F1 Score: 0.6341\n",
      "AUC-ROC: 0.4647\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.30      0.36        57\n",
      "           1       0.57      0.72      0.63        72\n",
      "\n",
      "    accuracy                           0.53       129\n",
      "   macro avg       0.51      0.51      0.50       129\n",
      "weighted avg       0.52      0.53      0.51       129\n",
      "\n",
      "\n",
      "=== TimeSeriesSplit 平均 ACC: 0.4884, F1: 0.4770, AUC-ROC: 0.4861 ===\n",
      "\n",
      "=== TimeSeriesSplit: LightGBM ===\n",
      "\n",
      "Fold 1/3 開始...\n",
      "Fold 1 - X_train shape: (130, 25)\n",
      "Fold 1 - X_val shape: (129, 25)\n",
      "Fold 1 - y_train shape: (130,)\n",
      "Fold 1 - y_val shape: (129,)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 66\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1124\n",
      "[LightGBM] [Info] Number of data points in the train set: 130, number of used features: 25\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 25 dense feature groups (0.00 MB) transferred to GPU in 0.003281 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Accuracy: 0.4419\n",
      "F1 Score: 0.2941\n",
      "AUC-ROC: 0.5347\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.81      0.54        52\n",
      "           1       0.60      0.19      0.29        77\n",
      "\n",
      "    accuracy                           0.44       129\n",
      "   macro avg       0.50      0.50      0.42       129\n",
      "weighted avg       0.52      0.44      0.39       129\n",
      "\n",
      "\n",
      "Fold 2/3 開始...\n",
      "Fold 2 - X_train shape: (259, 25)\n",
      "Fold 2 - X_val shape: (129, 25)\n",
      "Fold 2 - y_train shape: (259,)\n",
      "Fold 2 - y_val shape: (129,)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Number of positive: 141, number of negative: 118\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2183\n",
      "[LightGBM] [Info] Number of data points in the train set: 259, number of used features: 25\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 25 dense feature groups (0.01 MB) transferred to GPU in 0.002958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Accuracy: 0.4109\n",
      "F1 Score: 0.3770\n",
      "AUC-ROC: 0.4498\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.58      0.44        52\n",
      "           1       0.51      0.30      0.38        77\n",
      "\n",
      "    accuracy                           0.41       129\n",
      "   macro avg       0.43      0.44      0.41       129\n",
      "weighted avg       0.45      0.41      0.40       129\n",
      "\n",
      "\n",
      "Fold 3/3 開始...\n",
      "Fold 3 - X_train shape: (388, 25)\n",
      "Fold 3 - X_val shape: (129, 25)\n",
      "Fold 3 - y_train shape: (388,)\n",
      "Fold 3 - y_val shape: (129,)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Number of positive: 218, number of negative: 170\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 3243\n",
      "[LightGBM] [Info] Number of data points in the train set: 388, number of used features: 25\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 25 dense feature groups (0.01 MB) transferred to GPU in 0.003108 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Accuracy: 0.5116\n",
      "F1 Score: 0.5935\n",
      "AUC-ROC: 0.5046\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.35      0.39        57\n",
      "           1       0.55      0.64      0.59        72\n",
      "\n",
      "    accuracy                           0.51       129\n",
      "   macro avg       0.49      0.49      0.49       129\n",
      "weighted avg       0.50      0.51      0.50       129\n",
      "\n",
      "\n",
      "=== TimeSeriesSplit 平均 ACC: 0.4548, F1: 0.4216, AUC-ROC: 0.4964 ===\n",
      "\n",
      "=== TimeSeriesSplit: CatBoost ===\n",
      "\n",
      "Fold 1/3 開始...\n",
      "Fold 1 - X_train shape: (130, 25)\n",
      "Fold 1 - X_val shape: (129, 25)\n",
      "Fold 1 - y_train shape: (130,)\n",
      "Fold 1 - y_val shape: (129,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 2805.400001 Total: 4095.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4806\n",
      "F1 Score: 0.3619\n",
      "AUC-ROC: 0.5562\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.83      0.56        52\n",
      "           1       0.68      0.25      0.36        77\n",
      "\n",
      "    accuracy                           0.48       129\n",
      "   macro avg       0.55      0.54      0.46       129\n",
      "weighted avg       0.58      0.48      0.44       129\n",
      "\n",
      "\n",
      "Fold 2/3 開始...\n",
      "Fold 2 - X_train shape: (259, 25)\n",
      "Fold 2 - X_val shape: (129, 25)\n",
      "Fold 2 - y_train shape: (259,)\n",
      "Fold 2 - y_val shape: (129,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 2805.400001 Total: 4095.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3876\n",
      "F1 Score: 0.3577\n",
      "AUC-ROC: 0.4101\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.54      0.41        52\n",
      "           1       0.48      0.29      0.36        77\n",
      "\n",
      "    accuracy                           0.39       129\n",
      "   macro avg       0.41      0.41      0.39       129\n",
      "weighted avg       0.42      0.39      0.38       129\n",
      "\n",
      "\n",
      "Fold 3/3 開始...\n",
      "Fold 3 - X_train shape: (388, 25)\n",
      "Fold 3 - X_val shape: (129, 25)\n",
      "Fold 3 - y_train shape: (388,)\n",
      "Fold 3 - y_val shape: (129,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 2805.400001 Total: 4095.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5194\n",
      "F1 Score: 0.6220\n",
      "AUC-ROC: 0.4683\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.28      0.34        57\n",
      "           1       0.55      0.71      0.62        72\n",
      "\n",
      "    accuracy                           0.52       129\n",
      "   macro avg       0.49      0.49      0.48       129\n",
      "weighted avg       0.50      0.52      0.50       129\n",
      "\n",
      "\n",
      "=== TimeSeriesSplit 平均 ACC: 0.4625, F1: 0.4472, AUC-ROC: 0.4782 ===\n",
      "\n",
      "=== TimeSeriesSplit: MLP ===\n",
      "\n",
      "Fold 1/3 開始...\n",
      "Fold 1 - X_train shape: (130, 25)\n",
      "Fold 1 - X_val shape: (129, 25)\n",
      "Fold 1 - y_train shape: (130,)\n",
      "Fold 1 - y_val shape: (129,)\n",
      "Accuracy: 0.4574\n",
      "F1 Score: 0.4615\n",
      "AUC-ROC: 0.5320\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.56      0.45        52\n",
      "           1       0.57      0.39      0.46        77\n",
      "\n",
      "    accuracy                           0.46       129\n",
      "   macro avg       0.47      0.47      0.46       129\n",
      "weighted avg       0.49      0.46      0.46       129\n",
      "\n",
      "\n",
      "Fold 2/3 開始...\n",
      "Fold 2 - X_train shape: (259, 25)\n",
      "Fold 2 - X_val shape: (129, 25)\n",
      "Fold 2 - y_train shape: (259,)\n",
      "Fold 2 - y_val shape: (129,)\n",
      "Accuracy: 0.4884\n",
      "F1 Score: 0.5217\n",
      "AUC-ROC: 0.4888\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.52      0.45        52\n",
      "           1       0.59      0.47      0.52        77\n",
      "\n",
      "    accuracy                           0.49       129\n",
      "   macro avg       0.49      0.49      0.49       129\n",
      "weighted avg       0.51      0.49      0.49       129\n",
      "\n",
      "\n",
      "Fold 3/3 開始...\n",
      "Fold 3 - X_train shape: (388, 25)\n",
      "Fold 3 - X_val shape: (129, 25)\n",
      "Fold 3 - y_train shape: (388,)\n",
      "Fold 3 - y_val shape: (129,)\n",
      "Accuracy: 0.5116\n",
      "F1 Score: 0.5828\n",
      "AUC-ROC: 0.4845\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.39      0.41        57\n",
      "           1       0.56      0.61      0.58        72\n",
      "\n",
      "    accuracy                           0.51       129\n",
      "   macro avg       0.50      0.50      0.50       129\n",
      "weighted avg       0.51      0.51      0.51       129\n",
      "\n",
      "\n",
      "=== TimeSeriesSplit 平均 ACC: 0.4858, F1: 0.5220, AUC-ROC: 0.5018 ===\n",
      "\n",
      "=== TimeSeriesSplit: Stacking ===\n",
      "\n",
      "Fold 1/3 開始...\n",
      "Fold 1 - X_train shape: (130, 25)\n",
      "Fold 1 - X_val shape: (129, 25)\n",
      "Fold 1 - y_train shape: (130,)\n",
      "Fold 1 - y_val shape: (129,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The estimator function should be a classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 219\u001b[0m\n\u001b[0;32m    211\u001b[0m avg_acc_mlp, avg_f1_mlp, avg_auc_mlp \u001b[38;5;241m=\u001b[39m timeseries_cv_and_train(\n\u001b[0;32m    212\u001b[0m     X_full_scaled, y_full, \n\u001b[0;32m    213\u001b[0m     model_fn\u001b[38;5;241m=\u001b[39mmodel_fn_mlp, \n\u001b[0;32m    214\u001b[0m     n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[0;32m    215\u001b[0m     is_lstm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    216\u001b[0m )\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== TimeSeriesSplit: Stacking ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 219\u001b[0m avg_acc_stack, avg_f1_stack, avg_auc_stack \u001b[38;5;241m=\u001b[39m \u001b[43mtimeseries_cv_and_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_full_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_fn_stacking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_lstm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    224\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== TimeSeriesSplit: XGBoost GridSearch ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m avg_acc_xgb_grid, avg_f1_xgb_grid, avg_auc_xgb_grid \u001b[38;5;241m=\u001b[39m timeseries_cv_and_train(\n\u001b[0;32m    228\u001b[0m     X_full_scaled, y_full, \n\u001b[0;32m    229\u001b[0m     model_fn\u001b[38;5;241m=\u001b[39mmodel_fn_xgb_grid, \n\u001b[0;32m    230\u001b[0m     n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[0;32m    231\u001b[0m     is_lstm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    232\u001b[0m )\n",
      "Cell \u001b[1;32mIn[31], line 39\u001b[0m, in \u001b[0;36mtimeseries_cv_and_train\u001b[1;34m(X, y, model_fn, n_splits, is_lstm)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - y_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - y_val shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_val\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m model, pred_fn \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pred_fn(X_val)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "Cell \u001b[1;32mIn[33], line 89\u001b[0m, in \u001b[0;36mmodel_fn_stacking\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_fn_stacking\u001b[39m(X, y):\n\u001b[1;32m---> 89\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_stacking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, \u001b[38;5;28;01mlambda\u001b[39;00m X_val: model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "Cell \u001b[1;32mIn[30], line 104\u001b[0m, in \u001b[0;36mtrain_stacking\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"訓練 Stacking 模型。\"\"\"\u001b[39;00m\n\u001b[0;32m    103\u001b[0m stacking_clf \u001b[38;5;241m=\u001b[39m get_stacking_model()\n\u001b[1;32m--> 104\u001b[0m \u001b[43mstacking_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stacking_clf\n",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:349\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    347\u001b[0m transformed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:73\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get common fit operations.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     names, clfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:282\u001b[0m, in \u001b[0;36m_BaseHeterogeneousEnsemble._validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m estimators:\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_estimator_type(est):\n\u001b[1;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe estimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m should be a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    284\u001b[0m                 est\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_estimator_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m[\u001b[38;5;241m3\u001b[39m:]\n\u001b[0;32m    285\u001b[0m             )\n\u001b[0;32m    286\u001b[0m         )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m names, estimators\n",
      "\u001b[1;31mValueError\u001b[0m: The estimator function should be a classifier."
     ]
    }
   ],
   "source": [
    "# ============================== #\n",
    "#       7. 添加所有特徵              #\n",
    "# ============================== #\n",
    "\n",
    "# 添加技術指標、情緒變動特徵、滯後漲幅等\n",
    "df_merged = add_feature_engineering(df_merged)\n",
    "print(\"\\n添加所有特徵後的資料預覽：\")\n",
    "display(df_merged.head())\n",
    "\n",
    "# ============================== #\n",
    "#    8. 準備特徵與標準化           #\n",
    "# ============================== #\n",
    "\n",
    "# 定義特徵列表\n",
    "features = [\n",
    "    'mean_headline_sent',\n",
    "    'mean_content_sent',\n",
    "    'sp_close',\n",
    "    'sp_close_lag_1',\n",
    "    'sp_close_lag_2',\n",
    "    'sp_close_lag_3',\n",
    "    'MA_5',\n",
    "    'MA_10',\n",
    "    'RSI',\n",
    "    'MACD',\n",
    "    'MACD_signal',\n",
    "    'MACD_diff',\n",
    "    'BB_upper',\n",
    "    'BB_lower',\n",
    "    'sentiment_change_1',\n",
    "    'sentiment_change_2',\n",
    "    'sentiment_change_3',\n",
    "    'sentiment_lag_1',\n",
    "    'sentiment_lag_2',\n",
    "    'sentiment_lag_3',\n",
    "    'sp_return',\n",
    "    'sp_return_lag_1',\n",
    "    'sp_return_lag_2',\n",
    "    'sp_return_lag_3',\n",
    "    'sp_return_mean_5'\n",
    "]\n",
    "\n",
    "# 確認所有特徵都存在\n",
    "missing_features = [feat for feat in features if feat not in df_merged.columns]\n",
    "if missing_features:\n",
    "    print(f\"錯誤: 缺少特徵 {missing_features}\")\n",
    "else:\n",
    "    print(\"所有特徵均存在。\")\n",
    "\n",
    "# 填補 NaN 值並確保數據類型正確\n",
    "df_merged[features] = df_merged[features].astype(float).fillna(0)\n",
    "\n",
    "# 準備特徵和標籤\n",
    "X_full = df_merged[features].values\n",
    "y_full = df_merged['target'].values\n",
    "\n",
    "# 標準化特徵\n",
    "scaler = StandardScaler()\n",
    "X_full_scaled = scaler.fit_transform(X_full)\n",
    "print(\"[Info] 特徵標準化完成.\")\n",
    "print(f\"X_full_scaled shape: {X_full_scaled.shape}\")\n",
    "\n",
    "# ============================== #\n",
    "#         9. 交叉驗證與訓練        #\n",
    "# ============================== #\n",
    "\n",
    "# 定義模型函數\n",
    "def model_fn_rf(X, y):\n",
    "    model = train_random_forest(X, y)\n",
    "    return model, lambda X_val: model.predict(X_val)\n",
    "\n",
    "def model_fn_xgb(X, y):\n",
    "    model = train_xgboost(X, y)\n",
    "    return model, lambda X_val: model.predict(X_val)\n",
    "\n",
    "def model_fn_lightgbm(X, y):\n",
    "    model = train_lightgbm(X, y)\n",
    "    return model, lambda X_val: model.predict(X_val)\n",
    "\n",
    "def model_fn_catboost(X, y):\n",
    "    model = train_catboost(X, y)\n",
    "    return model, lambda X_val: model.predict(X_val)\n",
    "\n",
    "def model_fn_mlp(X, y):\n",
    "    model = train_mlp(X, y)\n",
    "    return model, lambda X_val: model.predict(X_val)\n",
    "\n",
    "def model_fn_stacking(X, y):\n",
    "    model = train_stacking(X, y)\n",
    "    return model, lambda X_val: model.predict(X_val)\n",
    "\n",
    "def model_fn_xgb_grid(X, y):\n",
    "    model = train_xgboost_gridsearch(X, y)\n",
    "    return model, lambda X_val: model.predict(X_val)\n",
    "\n",
    "def model_fn_xgb_random(X, y):\n",
    "    model = train_xgboost_randomsearch(X, y)\n",
    "    return model, lambda X_val: model.predict(X_val)\n",
    "\n",
    "# 定義超參數調整函數\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def train_xgboost_gridsearch(X_train, y_train):\n",
    "    \"\"\"\n",
    "    使用 GridSearchCV 進行超參數調整的 XGBoost 模型。\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.7, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "        'scale_pos_weight': [1, 2, 3]  # 根據類別不平衡調整\n",
    "    }\n",
    "    \n",
    "    clf = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=clf,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "def train_xgboost_randomsearch(X_train, y_train):\n",
    "    \"\"\"\n",
    "    使用 RandomizedSearchCV 進行超參數調整的 XGBoost 模型。\n",
    "    \"\"\"\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'subsample': [0.6, 0.7, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n",
    "        'gamma': [0, 0.1, 0.2, 0.3],\n",
    "        'reg_alpha': [0, 0.01, 0.1],\n",
    "        'reg_lambda': [1, 1.5, 2]\n",
    "    }\n",
    "    \n",
    "    clf = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=clf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=100,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters: {random_search.best_params_}\")\n",
    "    print(f\"Best cross-validation accuracy: {random_search.best_score_:.4f}\")\n",
    "    \n",
    "    best_model = random_search.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "# 執行交叉驗證\n",
    "print(\"\\n=== TimeSeriesSplit: Random Forest ===\")\n",
    "avg_acc_rf, avg_f1_rf, avg_auc_rf = timeseries_cv_and_train(\n",
    "    X_full_scaled, y_full, \n",
    "    model_fn=model_fn_rf, \n",
    "    n_splits=3, \n",
    "    is_lstm=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== TimeSeriesSplit: XGBoost ===\")\n",
    "avg_acc_xgb, avg_f1_xgb, avg_auc_xgb = timeseries_cv_and_train(\n",
    "    X_full_scaled, y_full, \n",
    "    model_fn=model_fn_xgb, \n",
    "    n_splits=3, \n",
    "    is_lstm=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== TimeSeriesSplit: LightGBM ===\")\n",
    "avg_acc_lgbm, avg_f1_lgbm, avg_auc_lgbm = timeseries_cv_and_train(\n",
    "    X_full_scaled, y_full, \n",
    "    model_fn=model_fn_lightgbm, \n",
    "    n_splits=3, \n",
    "    is_lstm=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== TimeSeriesSplit: CatBoost ===\")\n",
    "avg_acc_cb, avg_f1_cb, avg_auc_cb = timeseries_cv_and_train(\n",
    "    X_full_scaled, y_full, \n",
    "    model_fn=model_fn_catboost, \n",
    "    n_splits=3, \n",
    "    is_lstm=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== TimeSeriesSplit: MLP ===\")\n",
    "avg_acc_mlp, avg_f1_mlp, avg_auc_mlp = timeseries_cv_and_train(\n",
    "    X_full_scaled, y_full, \n",
    "    model_fn=model_fn_mlp, \n",
    "    n_splits=3, \n",
    "    is_lstm=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== TimeSeriesSplit: Stacking ===\")\n",
    "avg_acc_stack, avg_f1_stack, avg_auc_stack = timeseries_cv_and_train(\n",
    "    X_full_scaled, y_full, \n",
    "    model_fn=model_fn_stacking, \n",
    "    n_splits=3, \n",
    "    is_lstm=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== TimeSeriesSplit: XGBoost GridSearch ===\")\n",
    "avg_acc_xgb_grid, avg_f1_xgb_grid, avg_auc_xgb_grid = timeseries_cv_and_train(\n",
    "    X_full_scaled, y_full, \n",
    "    model_fn=model_fn_xgb_grid, \n",
    "    n_splits=3, \n",
    "    is_lstm=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== TimeSeriesSplit: XGBoost RandomSearch ===\")\n",
    "avg_acc_xgb_random, avg_f1_xgb_random, avg_auc_xgb_random = timeseries_cv_and_train(\n",
    "    X_full_scaled, y_full, \n",
    "    model_fn=model_fn_xgb_random, \n",
    "    n_splits=3, \n",
    "    is_lstm=False\n",
    ")\n",
    "\n",
    "# 選擇最佳模型\n",
    "model_acc = {\n",
    "    \"RandomForest\": avg_acc_rf,\n",
    "    \"XGBoost\": avg_acc_xgb,\n",
    "    \"LightGBM\": avg_acc_lgbm,\n",
    "    \"CatBoost\": avg_acc_cb,\n",
    "    \"MLP\": avg_acc_mlp,\n",
    "    \"Stacking\": avg_acc_stack,\n",
    "    \"XGBoost_GridSearch\": avg_acc_xgb_grid,\n",
    "    \"XGBoost_RandomSearch\": avg_acc_xgb_random\n",
    "}\n",
    "\n",
    "best_model_name = max(model_acc, key=model_acc.get)\n",
    "best_acc = model_acc[best_model_name]\n",
    "\n",
    "print(f\"\\n[Best Model] {best_model_name}, ACC={best_acc:.4f}\\n\")\n",
    "\n",
    "# ============================== #\n",
    "#        10. 訓練最佳模型           #\n",
    "# ============================== #\n",
    "\n",
    "# 分割訓練集和測試集的比例\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(df_merged) * split_ratio)\n",
    "\n",
    "# 提取訓練集和測試集\n",
    "df_train = df_merged.iloc[:split_index].copy()\n",
    "df_test = df_merged.iloc[split_index:].copy()\n",
    "\n",
    "# 確保 'date' 欄位存在\n",
    "if 'date' not in df_test.columns:\n",
    "    raise KeyError(\"'date' 欄位在測試集中不存在。請檢查特徵工程和數據分割步驟。\")\n",
    "\n",
    "# 準備訓練集和測試集的特徵和標籤\n",
    "X_train, X_test = X_full_scaled[:split_index], X_full_scaled[split_index:]\n",
    "y_train, y_test = y_full[:split_index], y_full[split_index:]\n",
    "\n",
    "print(f\"訓練集大小: {X_train.shape[0]}\")\n",
    "print(f\"測試集大小: {X_test.shape[0]}\")\n",
    "\n",
    "# 處理類別不平衡（過採樣）\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"重新採樣後訓練集大小: {X_train_resampled.shape[0]}\")\n",
    "print(f\"重新採樣後測試集大小: {X_test.shape[0]}\")\n",
    "\n",
    "# 定義並訓練最佳模型\n",
    "def get_best_model(model_name):\n",
    "    if model_name == \"RandomForest\":\n",
    "        return train_random_forest(X_train_resampled, y_train_resampled)\n",
    "    elif model_name == \"XGBoost\":\n",
    "        return train_xgboost(X_train_resampled, y_train_resampled)\n",
    "    elif model_name == \"LightGBM\":\n",
    "        return train_lightgbm(X_train_resampled, y_train_resampled)\n",
    "    elif model_name == \"CatBoost\":\n",
    "        return train_catboost(X_train_resampled, y_train_resampled)\n",
    "    elif model_name == \"MLP\":\n",
    "        return train_mlp(X_train_resampled, y_train_resampled)  # 若使用 PyTorch 的 MLP，需另外處理\n",
    "    elif model_name == \"Stacking\":\n",
    "        return train_stacking(X_train_resampled, y_train_resampled)  # 使用 GPU 支持的 Stacking 模型\n",
    "    elif model_name == \"XGBoost_GridSearch\":\n",
    "        return train_xgboost_gridsearch(X_train_resampled, y_train_resampled)\n",
    "    elif model_name == \"XGBoost_RandomSearch\":\n",
    "        return train_xgboost_randomsearch(X_train_resampled, y_train_resampled)\n",
    "    else:\n",
    "        raise ValueError(\"未知的模型名稱\")\n",
    "\n",
    "# 獲取最佳模型\n",
    "final_model = get_best_model(best_model_name)\n",
    "\n",
    "# 在測試集上進行預測\n",
    "if best_model_name in [\"Stacking\"]:\n",
    "    y_pred_test = final_model.predict(X_test)\n",
    "    y_prob_test = final_model.predict_proba(X_test)[:,1]\n",
    "else:\n",
    "    y_pred_test = final_model.predict(X_test)\n",
    "    if hasattr(final_model, \"predict_proba\"):\n",
    "        y_prob_test = final_model.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        y_prob_test = None\n",
    "\n",
    "# 添加預測結果到 df_test\n",
    "df_test.loc[:, 'y_pred'] = y_pred_test\n",
    "\n",
    "\n",
    "# 評估模型\n",
    "def evaluate_final_model(y_true, y_pred, y_prob):\n",
    "    \"\"\"評估最終模型。\"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
    "    print(f\"Final Model Accuracy: {acc:.4f}\")\n",
    "    print(f\"Final Model F1 Score: {f1:.4f}\")\n",
    "    if auc is not None:\n",
    "        print(f\"Final Model AUC-ROC: {auc:.4f}\")\n",
    "    print(\"\\nFinal Model Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return acc, f1, auc\n",
    "\n",
    "acc_test, f1_test, auc_test = evaluate_final_model(y_test, y_pred_test, y_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred_smooth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m smooth_curve(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m], window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 設定日期為索引（如果尚未設定）\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     16\u001b[0m df_test\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 創建一個雙 y 軸的圖表\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\morri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "# ============================== #\n",
    "#        7. 視覺化結果            #\n",
    "# ============================== #\n",
    "\n",
    "def smooth_curve(y, window=5):\n",
    "    \"\"\"使用移動平均平滑曲線。\"\"\"\n",
    "    return pd.Series(y).rolling(window=window, min_periods=1).mean().values\n",
    "\n",
    "# 平滑處理\n",
    "df_test['sp_close_smooth'] = smooth_curve(df_test['sp_close'], window=5)\n",
    "df_test['mean_headline_sent_smooth'] = smooth_curve(df_test['mean_headline_sent'], window=5)\n",
    "df_test['y_pred_smooth'] = smooth_curve(df_test['y_pred'], window=5)\n",
    "\n",
    "# 設定日期為索引（如果尚未設定）\n",
    "df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "df_test.set_index('date', inplace=True)\n",
    "\n",
    "# 創建一個雙 y 軸的圖表\n",
    "fig, ax1 = plt.subplots(figsize=(14,7))\n",
    "\n",
    "# 繪製 S&P500 指數\n",
    "ax1.plot(df_test.index, df_test['sp_close_smooth'], color='blue', label='S&P 500')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('S&P500', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# 繪製情緒分析分數\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_test.index, df_test['mean_headline_sent_smooth'], color='green', label='avg sentiment(smoothed)')\n",
    "ax2.set_ylabel('sentiment', color='green')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "# 繪製預測結果\n",
    "plt.plot(df_test.index, df_test['y_pred_smooth'], color='red', linestyle='--', label='predict (smothed)')\n",
    "\n",
    "# 合併圖例\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "plt.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
    "\n",
    "plt.title(f\"Final Model ({best_model_name}) on Test Data (Smoothed)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_data.csv 已輸出。\n"
     ]
    }
   ],
   "source": [
    "# ============================== #\n",
    "#       8. 輸出合併資料              #\n",
    "# ============================== #\n",
    "\n",
    "df_merged.to_csv(\"merged_data.csv\", index=False)\n",
    "print(\"merged_data.csv 已輸出。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
